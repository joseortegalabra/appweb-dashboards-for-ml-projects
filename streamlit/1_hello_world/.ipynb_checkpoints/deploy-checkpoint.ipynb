{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea04d11-b156-4dff-ac80-08ab3e80c79b",
   "metadata": {},
   "source": [
    "# Deploy streamlit app into a cloud run (gcp)\n",
    "Following the ideas of:\n",
    "- deploy streamlit app in cloud run: https://medium.com/@faizififita1/how-to-deploy-your-streamlit-web-app-to-google-cloud-run-ba776487c5fe\n",
    "- deploy streamlit app into google app engine: https://dev.to/whitphx/how-to-deploy-streamlit-apps-to-google-app-engine-407o\n",
    "- deploy a flask app into a cloud run: my previous codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc770c07-ce2a-492f-97ac-bd9fb8aaa545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e1ce3c5",
   "metadata": {},
   "source": [
    "## Upload artifact registry\n",
    "Estos códigos se podrían correr en la consola SDK de google, así como correrlos en un notebook.\n",
    "Para un data scientist poco especializado en prácticas de devops, utilizar un notebook es más inuitivo de utilizar\n",
    "\n",
    "##### Pasos previos\n",
    "- Pararse en la carpeta root de la app (crear este notebook en el root)\n",
    "- Tener creados scripts a contenizar y subirse a cloud run\n",
    "\n",
    "\n",
    "revisar este punto\n",
    "- Crear Dockerfile en el root (un ejemplo de Dockerfile se puede encontrar en: https://firebase.google.com/docs/hosting/cloud-run?hl=es-419#python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f36e8",
   "metadata": {},
   "source": [
    "##### Estructura Notebook Deploy app web\n",
    "Existen dos métodos para hacer el deploy, almacenar la imagen docker en artifact registry (forma actual) y almacenar la imagen en container registry (forma antigua y cada vez más deprecated). En este Notebook por ser el primer y el de ejemplo se va a hacer el deploy de ambas formas primero en artifact registry y posteriormente en container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c5998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646304fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf9ae26",
   "metadata": {},
   "source": [
    "## INICIALIZAR: SET PROYECT GCP\n",
    "\n",
    "**Para correr comando de consola en un jupyter notebook y que además se le puedan pasar variables del notebook al comando se debe utilizar el signo peso ($) y no utilizar el comando de asignación (=)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338a3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv # package used in jupyter notebook to read the variables in file .env\n",
    "\n",
    "\"\"\" get env variable from .env \"\"\"\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "\"\"\" Read env variables \"\"\"\n",
    "env_var_project_gcp = os.environ.get(\"PROJECT_GCP\", \"\")\n",
    "\n",
    "# SET SERVICE ACCOUNT GCP AND PROJECT\n",
    "PROJECT_ID = env_var_project_gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6518dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "REGION = 'us-east1'\n",
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e91a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0591b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e1c63e",
   "metadata": {},
   "source": [
    "## ------- ARTIFACT REGISTRY -------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2ce87",
   "metadata": {},
   "source": [
    "Artifact registry es el reemplazo de container registry y el recomendado por google. La única diferencia es que se guarda la imagen en este nuevo servicio y se necesita correr otros comando\n",
    "\n",
    "\n",
    "Además, cada vez que se sube una imagen nueva a artifact registry (volver a ejecutar el comando correspondiente de gcloud), esta recibe la etiqueta latest y es la que se utiliza para crear/actualizar la cloud run creada\n",
    "\n",
    "Subir la imagen a artifact Registry requiere más pasos que subirla a container registry\n",
    "\n",
    "Documentación integración cloud build con Artifact Registry: https://cloud.google.com/artifact-registry/docs/configure-cloud-build?hl=es-419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b6f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c45b9db",
   "metadata": {},
   "source": [
    "### Paso 0: Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03167e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARÁMETROS \n",
    "\n",
    "# generales gcp\n",
    "PROJECT_ID = 'cmpc-innovation-cd4ml-test'\n",
    "REGION = 'us-east1'\n",
    "\n",
    "# nombre del repo\n",
    "NAME_REPO = 'repo-app-web-1-hello-world-streamlit'\n",
    "FORMAT_REPO = 'docker'\n",
    "DESCRIPTION_REPO = \"repo web app 1 hello world streamlit\"\n",
    "\n",
    "# nombre de la imagen\n",
    "NAME_IMAGE = '1-hello-world-stremalit'\n",
    "\n",
    "# nombre del cloud run que va a alojar la app web\n",
    "NAME_CLOUD_RUN = 'app-web-1-hello-world-streamlit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fc138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5526c44e",
   "metadata": {},
   "source": [
    "### Paso 1. Crear repositorio en artifact registry (si es que este no existe)\n",
    "A diferencia de container registry que era automática, en artifact registry hay que crearlo.\n",
    "\n",
    "En container registry solo se creaba una imagen y se almacenaban diferentes versiones de la imagen, por el contrario en artifact registry se crea un repo el cual puede tener múltiples imágenes y cada una tener diferentes versiones\n",
    "\n",
    "\n",
    "Documentación: crear repo en artifact registry: https://cloud.google.com/artifact-registry/docs/repositories/create-repos#gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceae1f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# crear repo\n",
    "! gcloud artifacts repositories create $NAME_REPO \\\n",
    "--repository-format $FORMAT_REPO \\\n",
    "--location $REGION \\\n",
    "--description \"$DESCRIPTION_REPO\" \\\n",
    "--async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab2428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f594f3",
   "metadata": {},
   "source": [
    "### Paso 2: Configurar una compilación de Docker\n",
    "\n",
    "Es necesario crear un **yaml** con la configuración para compilar la imagen docker en Artifact Registry.\n",
    "\n",
    "Tiene la siguiente forma\n",
    "\n",
    "<code>\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [ 'build', '-t', '${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}', '.' ]\n",
    "images:\n",
    "- '${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}'\n",
    "<code>\n",
    "    \n",
    "\n",
    "**Este un ARCHIVO GENÉRICO que se puede reciclar porque está parametrizado para funcionar con cualquier repo docker en artifact registry** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13b0ae",
   "metadata": {},
   "source": [
    "--> Corriendo la siguiente línea de código se crea un archivo yaml con la configuración deseada. \n",
    "\n",
    "Documentación: https://stackabuse.com/reading-and-writing-yaml-to-a-file-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8516214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98471485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear diccionario python con el contenido del yaml cloudbuild genérico\n",
    "\n",
    "dict_python_yaml_cloudbuild = {'steps': [{'name': 'gcr.io/cloud-builders/docker',\n",
    "   'args': ['build', '-t', '${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}', '.']}],\n",
    " 'images': ['${_LOCATION}-docker.pkg.dev/$PROJECT_ID/${_REPOSITORY}/${_IMAGE}']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf1a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar diccionario en formato yaml\n",
    "\n",
    "with open(r'cloudbuild.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict_python_yaml_cloudbuild, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e475e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b267e53",
   "metadata": {},
   "source": [
    "### Paso 3. Crear Dockerfile\n",
    "\n",
    "Igual que el paso anterior, se necesita crear en este caso, el Dockerfile para poder subir la imagen al Artifact Registry. Por lo general, el dockerfile, se crea de forma manual.\n",
    "\n",
    "En este ejemplo, se define el contenido del dockerfile dentro de un string lo que permite que en un futuro se pueda cambiar vía código por ejemplo:\n",
    "- versión de python\n",
    "- Listado de archivos que van a formar parte de la imagen\n",
    "- Librerías que necesita la imagen para funcionar\n",
    "\n",
    "Por lo general, la mayoría de las veces, el Dockerfile no necesita ser modificado salvo que se desee cambiar la versión de python o que se requiera agregar nuevas librerías en el desarrollo. Por lo que corriendo el sgte código se obtiene el Dockerfile de la app web\n",
    "\n",
    "https://prnt.sc/uwBOFChK8QU8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0e2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A STRING THAT REPRESENT THE DOCKER FILE\n",
    "\n",
    "################## DOCKER FILE TO DEPLOY A FLASK APP ##################\n",
    "# string_dockerfile = '''FROM python:3.7.5-slim-buster\n",
    "# ENV PYTHONUNBUFFERED True\n",
    "\n",
    "# # Copy local code to the container image.\n",
    "# ENV APP_HOME /app\n",
    "# WORKDIR $APP_HOME\n",
    "# COPY . ./\n",
    "\n",
    "# # Install production dependencies.\n",
    "# RUN pip install Flask gunicorn pandas numpy plotly google-cloud-bigquery db-dtypes\n",
    "\n",
    "# CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 app:app\n",
    "# '''\n",
    "\n",
    "################## DOCKER FILE TO DEPLOY A STREAMLIT APP ##################\n",
    "# following the idea of docker file presents in: https://dev.to/whitphx/how-to-deploy-streamlit-apps-to-google-app-engine-407o\n",
    "\n",
    "\n",
    "### mi codigo en base a flask que no funciono\n",
    "# string_dockerfile = '''FROM python:3.7.5-slim-buster\n",
    "# ENV PYTHONUNBUFFERED True\n",
    "\n",
    "# # Copy local code to the container image.\n",
    "# ENV APP_HOME /app\n",
    "# WORKDIR $APP_HOME\n",
    "# COPY . ./\n",
    "\n",
    "# # Install production dependencies.\n",
    "# RUN pip install streamlit gunicorn\n",
    "\n",
    "# CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 app:app\n",
    "# '''\n",
    "\n",
    "string_dockerfile = '''\n",
    "FROM python:3.8\n",
    "EXPOSE 8080\n",
    "WORKDIR /app\n",
    "COPY . ./\n",
    "RUN pip install streamlit gunicorn\n",
    "ENTRYPOINT [\"streamlit\", \"run\", \"app.py\", \"--server.port=8080\", \"--server.address=0.0.0.0\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc57cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar dockerfile\n",
    "with open('Dockerfile', 'w') as file:\n",
    "    file.write(string_dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b43e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15903a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba335ac5",
   "metadata": {},
   "source": [
    "### Paso 4: Contenerizar (imagen docker) códigos app web utlizando cloud build y subirlas a artifact registry\n",
    "- En este paso se crea una imagen docker con los códigos necesarios para la app web y posterior se procede a subir dicha imagen a Artifact Registry (utilizando como base el archivo \"cloudbuild.yaml\" que llama al \"Dockerfile\", creados en los pasos anteriores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f993074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 6 file(s) totalling 72.5 KiB before compression.\n",
      "Uploading tarball of [.] to [gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1705969349.360434-f036cb381876402ca9f180d144a3cdb2.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/cmpc-innovation-cd4ml-test/locations/global/builds/68a3c6c8-d07b-4a0d-9c10-16bd39314756].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/68a3c6c8-d07b-4a0d-9c10-16bd39314756?project=724348686027 ].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting build \"68a3c6c8-d07b-4a0d-9c10-16bd39314756\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1705969349.360434-f036cb381876402ca9f180d144a3cdb2.tgz#1705969342390019\n",
      "Copying gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1705969349.360434-f036cb381876402ca9f180d144a3cdb2.tgz#1705969342390019...\n",
      "/ [0 files][    0.0 B/ 20.9 KiB]                                                \n",
      "/ [1 files][ 20.9 KiB/ 20.9 KiB]                                                \n",
      "\n",
      "Operation completed over 1 objects/20.9 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon   80.9kB\n",
      "\n",
      "\n",
      "Step 1/6 : FROM python:3.8\n",
      "3.8: Pulling from library/python\n",
      "1b13d4e1a46e: Already exists\n",
      "1c74526957fc: Already exists\n",
      "30d855997954: Pulling fs layer\n",
      "ad5739181616: Pulling fs layer\n",
      "75e2b45cbee5: Pulling fs layer\n",
      "76c111f84668: Pulling fs layer\n",
      "f4cb18646a15: Pulling fs layer\n",
      "0a329b671abf: Pulling fs layer\n",
      "76c111f84668: Waiting\n",
      "f4cb18646a15: Waiting\n",
      "0a329b671abf: Waiting\n",
      "75e2b45cbee5: Verifying Checksum\n",
      "75e2b45cbee5: Download complete\n",
      "30d855997954: Verifying Checksum\n",
      "30d855997954: Download complete\n",
      "f4cb18646a15: Verifying Checksum\n",
      "f4cb18646a15: Download complete\n",
      "76c111f84668: Verifying Checksum\n",
      "76c111f84668: Download complete\n",
      "0a329b671abf: Verifying Checksum\n",
      "0a329b671abf: Download complete\n",
      "ad5739181616: Verifying Checksum\n",
      "ad5739181616: Download complete\n",
      "30d855997954: Pull complete\n",
      "ad5739181616: Pull complete\n",
      "75e2b45cbee5: Pull complete\n",
      "76c111f84668: Pull complete\n",
      "f4cb18646a15: Pull complete\n",
      "0a329b671abf: Pull complete\n",
      "Digest: sha256:22b8bf2be7a50eeb14b01322e580485681017032a720604baab1643a90a6b794\n",
      "Status: Downloaded newer image for python:3.8\n",
      " ---> 8a9041560010\n",
      "Step 2/6 : EXPOSE 8080\n",
      " ---> Running in 0ecb2dfa25ca\n",
      "Removing intermediate container 0ecb2dfa25ca\n",
      " ---> dcec1280e836\n",
      "Step 3/6 : WORKDIR /app\n",
      " ---> Running in fb149655e855\n",
      "Removing intermediate container fb149655e855\n",
      " ---> 668bb413d94b\n",
      "Step 4/6 : COPY . ./\n",
      " ---> 77976c475fe6\n",
      "Step 5/6 : RUN pip install streamlit gunicorn\n",
      " ---> Running in a27c967f140b\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.30.0-py2.py3-none-any.whl (8.4 MB)\n",
      "     ???????????????????????????????????????? 8.4/8.4 MB 29.4 MB/s eta 0:00:00\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "     ???????????????????????????????????????? 80.2/80.2 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting protobuf<5,>=3.20\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "     ?????????????????????????????????????? 294.6/294.6 kB 39.1 MB/s eta 0:00:00\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "     ???????????????????????????????????????? 4.8/4.8 MB 59.4 MB/s eta 0:00:00\n",
      "Collecting tornado<7,>=6.0.3\n",
      "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "     ?????????????????????????????????????? 435.4/435.4 kB 45.0 MB/s eta 0:00:00\n",
      "Collecting pillow<11,>=7.1.0\n",
      "  Downloading pillow-10.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "     ???????????????????????????????????????? 4.5/4.5 MB 65.9 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=6.0\n",
      "  Downloading pyarrow-15.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (38.4 MB)\n",
      "     ???????????????????????????????????????? 38.4/38.4 MB 36.1 MB/s eta 0:00:00\n",
      "Collecting tenacity<9,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "     ?????????????????????????????????????? 196.4/196.4 kB 28.9 MB/s eta 0:00:00\n",
      "Collecting click<9,>=7.0\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ???????????????????????????????????????? 97.9/97.9 kB 18.3 MB/s eta 0:00:00\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting python-dateutil<3,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ?????????????????????????????????????? 247.7/247.7 kB 34.8 MB/s eta 0:00:00\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting requests<3,>=2.27\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ???????????????????????????????????????? 62.6/62.6 kB 11.5 MB/s eta 0:00:00\n",
      "Collecting validators<1,>=0.2\n",
      "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "     ?????????????????????????????????????? 996.9/996.9 kB 68.1 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata<8,>=1.4\n",
      "  Downloading importlib_metadata-7.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting numpy<2,>=1.19.3\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "     ???????????????????????????????????????? 17.3/17.3 MB 60.6 MB/s eta 0:00:00\n",
      "Collecting pandas<3,>=1.3.0\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "     ???????????????????????????????????????? 12.4/12.4 MB 79.1 MB/s eta 0:00:00\n",
      "Collecting rich<14,>=10.14.0\n",
      "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "     ?????????????????????????????????????? 240.6/240.6 kB 23.7 MB/s eta 0:00:00\n",
      "Collecting watchdog>=2.1.5\n",
      "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "     ???????????????????????????????????????? 82.1/82.1 kB 11.5 MB/s eta 0:00:00\n",
      "Collecting tzlocal<6,>=1.1\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Collecting packaging<24,>=16.8\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     ???????????????????????????????????????? 53.0/53.0 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<5,>=4.3.0\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     ???????????????????????????????????????? 55.8/55.8 kB 9.0 MB/s eta 0:00:00\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "     ?????????????????????????????????????? 133.2/133.2 kB 21.6 MB/s eta 0:00:00\n",
      "Collecting jsonschema>=3.0\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "     ???????????????????????????????????????? 85.5/85.5 kB 14.7 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ???????????????????????????????????????? 62.7/62.7 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "     ?????????????????????????????????????? 346.6/346.6 kB 39.0 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "     ?????????????????????????????????????? 502.5/502.5 kB 48.2 MB/s eta 0:00:00\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "     ???????????????????????????????????????? 61.6/61.6 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "     ?????????????????????????????????????? 162.5/162.5 kB 24.0 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "     ?????????????????????????????????????? 141.1/141.1 kB 20.1 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "     ?????????????????????????????????????? 104.6/104.6 kB 15.7 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ???????????????????????????????????????? 87.5/87.5 kB 14.8 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "     ???????????????????????????????????????? 1.2/1.2 MB 72.3 MB/s eta 0:00:00\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-manylinux1_x86_64.whl (74 kB)\n",
      "     ???????????????????????????????????????? 74.0/74.0 kB 14.3 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.32.1-py3-none-any.whl (26 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     ???????????????????????????????????????? 60.8/60.8 kB 11.0 MB/s eta 0:00:00\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "     ???????????????????????????????????????? 1.2/1.2 MB 68.1 MB/s eta 0:00:00\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, zipp, watchdog, validators, urllib3, tzdata, typing-extensions, tornado, toolz, toml, tenacity, smmap, six, rpds-py, pygments, protobuf, pkgutil-resolve-name, pillow, packaging, numpy, mdurl, MarkupSafe, idna, click, charset-normalizer, certifi, cachetools, blinker, backports.zoneinfo, attrs, tzlocal, requests, referencing, python-dateutil, pyarrow, markdown-it-py, jinja2, importlib-resources, importlib-metadata, gunicorn, gitdb, rich, pydeck, pandas, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-2.1.4 altair-5.2.0 attrs-23.2.0 backports.zoneinfo-0.2.1 blinker-1.7.0 cachetools-5.3.2 certifi-2023.11.17 charset-normalizer-3.3.2 click-8.1.7 gitdb-4.0.11 gitpython-3.1.41 gunicorn-21.2.0 idna-3.6 importlib-metadata-7.0.1 importlib-resources-6.1.1 jinja2-3.1.3 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.24.4 packaging-23.2 pandas-2.0.3 pillow-10.2.0 pkgutil-resolve-name-1.3.10 protobuf-4.25.2 pyarrow-15.0.0 pydeck-0.8.1b0 pygments-2.17.2 python-dateutil-2.8.2 pytz-2023.3.post1 referencing-0.32.1 requests-2.31.0 rich-13.7.0 rpds-py-0.17.1 six-1.16.0 smmap-5.0.1 streamlit-1.30.0 tenacity-8.2.3 toml-0.10.2 toolz-0.12.0 tornado-6.4 typing-extensions-4.9.0 tzdata-2023.4 tzlocal-5.2 urllib3-2.1.0 validators-0.22.0 watchdog-3.0.0 zipp-3.17.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container a27c967f140b\n",
      " ---> ce845160976e\n",
      "Step 6/6 : ENTRYPOINT [\"streamlit\", \"run\", \"app.py\", \"--server.port=8080\", \"--server.address=0.0.0.0\"]\n",
      " ---> Running in dfdcd196b8a5\n",
      "Removing intermediate container dfdcd196b8a5\n",
      " ---> d4d2f874e567\n",
      "Successfully built d4d2f874e567\n",
      "Successfully tagged us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-app-web-1-hello-world-streamlit/1-hello-world-stremalit:latest\n",
      "PUSH\n",
      "Pushing us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-app-web-1-hello-world-streamlit/1-hello-world-stremalit\n",
      "The push refers to repository [us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-app-web-1-hello-world-streamlit/1-hello-world-stremalit]\n",
      "b615630356e1: Preparing\n",
      "de440d37a17b: Preparing\n",
      "2ff8709eed50: Preparing\n",
      "52872001ed86: Preparing\n",
      "be334ce242ed: Preparing\n",
      "5a89aa9cf506: Preparing\n",
      "f757a77eef71: Preparing\n",
      "a876dfc51caa: Preparing\n",
      "5bb1de08f5af: Preparing\n",
      "0dfa23fffa41: Preparing\n",
      "aa904f36746c: Preparing\n",
      "f757a77eef71: Waiting\n",
      "a876dfc51caa: Waiting\n",
      "5bb1de08f5af: Waiting\n",
      "0dfa23fffa41: Waiting\n",
      "aa904f36746c: Waiting\n",
      "5a89aa9cf506: Waiting\n",
      "de440d37a17b: Pushed\n",
      "2ff8709eed50: Pushed\n",
      "be334ce242ed: Pushed\n",
      "52872001ed86: Pushed\n",
      "f757a77eef71: Pushed\n",
      "5a89aa9cf506: Pushed\n",
      "0dfa23fffa41: Pushed\n",
      "b615630356e1: Pushed\n",
      "5bb1de08f5af: Pushed\n",
      "aa904f36746c: Pushed\n",
      "a876dfc51caa: Pushed\n",
      "latest: digest: sha256:5d2b509353f64da65f9faa53b41b7d1768492a32130e551cda4ecaca9512fe88 size: 2636\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                    IMAGES                                                                                                                     STATUS\n",
      "68a3c6c8-d07b-4a0d-9c10-16bd39314756  2024-01-23T00:22:22+00:00  2M21S     gs://cmpc-innovation-cd4ml-test_cloudbuild/source/1705969349.360434-f036cb381876402ca9f180d144a3cdb2.tgz  us-east1-docker.pkg.dev/cmpc-innovation-cd4ml-test/repo-app-web-1-hello-world-streamlit/1-hello-world-stremalit (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# OJO: Los nombres de las variables en el comando gcloud corresponden a las variables definidas en el archivo de configuración \n",
    "# yaml\n",
    "\n",
    "# OJO2: para pasar el nombre de las variables (al igual que siempre) se debe de utilizar el signo dolar \"$\" pero debe\n",
    "# de estar entre comillas (para que se entienda que es la variable a reemplazar en el yaml de configuración)\n",
    "\n",
    "# OJO3: debe ser comillas dobles y sin espacios para no tener problemas\n",
    "\n",
    "! gcloud builds submit \\\n",
    "    --config=cloudbuild.yaml \\\n",
    "    --substitutions=_LOCATION=\"$REGION\",_REPOSITORY=\"$NAME_REPO\",_IMAGE=\"$NAME_IMAGE\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fba7d5",
   "metadata": {},
   "source": [
    "### Paso 5:  Deploy de la imagen del contenedor de artifact registry en cloud run\n",
    "Se debe de correr el comando gloud run deploy (igual que en el container registry) con la única diferencia en que cambia la ubicación de la imagen la cual es:\n",
    "\n",
    " {LOCATION}-docker.pkg.dev/{PROJECT}/{REPOSITORY}/{IMAGE}/\n",
    " \n",
    " \n",
    "\n",
    "**IMPORTANTE: POR PROBLEMAS DE PERMISOS, EL CLOUD RUN ESTÁ CONFIGURADO PARA QUE CUALQUIERA CON EL LINK PUEDA ACCEDER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f4016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deploying container to Cloud Run service [app-web-1-hello-world-streamlit] in project [cmpc-innovation-cd4ml-test] region [us-east1]\n",
      "Deploying...\n",
      "Setting IAM Policy......................done\n",
      "Creating Revision...............done\n",
      "Routing traffic.......................................................................................................................................................................................................................................................................done\n",
      "Done.\n",
      "Service [app-web-1-hello-world-streamlit] revision [app-web-1-hello-world-streamlit-00002-joq] has been deployed and is serving 100 percent of traffic.\n",
      "Service URL: https://app-web-1-hello-world-streamlit-z33tzzez7a-ue.a.run.app\n"
     ]
    }
   ],
   "source": [
    "! gcloud run deploy $NAME_CLOUD_RUN \\\n",
    "    --image $REGION-docker.pkg.dev/$PROJECT_ID/$NAME_REPO/$NAME_IMAGE \\\n",
    "    --region $REGION \\\n",
    "    --allow-unauthenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5885bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38981143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6bb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77832b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067aab46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4000f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
